{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2dcf29f",
   "metadata": {},
   "source": [
    "City Neighborhood Classifier \n",
    "\n",
    "CS 305: Machine Learning Fall 2021\n",
    "\n",
    "Sara Clark, Christine Pourheydarian, Jiawei Liu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1771af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (1.5.12)\n",
      "Requirement already satisfied: six>=1.10 in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: urllib3 in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (1.26.4)\n",
      "Requirement already satisfied: python-slugify in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: tqdm in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (4.59.0)\n",
      "Requirement already satisfied: certifi in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: requests in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/saraclark/opt/anaconda3/lib/python3.8/site-packages (from requests->kaggle) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39ef147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54351311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['20170905' 0 None 12147973]\n",
      " ['20170904' 0 None 12147973]\n",
      " ['20170903' 0 None 12147973]\n",
      " ...\n",
      " ['20160908' 0 None 14504422]\n",
      " ['20160907' 0 None 14504422]\n",
      " ['20160906' 0 None 14504422]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "importing the calendar.csv data. \n",
    "listing id stays a number\n",
    "date is kept in its form but has the dashes removed\n",
    "available: if f, then becomes 0. if t, then becomes 1. \n",
    "price: converted from currency to a double. if there is no price, the value inserted is None. \n",
    "'''\n",
    "\n",
    "\n",
    "from re import sub\n",
    "from decimal import Decimal\n",
    "\n",
    "\n",
    "calendar_csvfile = open('archive/calendar.csv', 'r')#listing_id,date,available,price\n",
    "reader = csv.reader(calendar_csvfile, delimiter=',', quotechar='\"')\n",
    "calendar_data = []\n",
    "\n",
    "for row in reader: \n",
    "    r  = [ ]\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            date = (row[1]).replace(\"-\", \"\")\n",
    "            r.append(date)\n",
    "        elif i == 1:\n",
    "            available = 0 if row[2] == \"f\" else 1 #f: 0, t: 1 \n",
    "            r.append(available)\n",
    "        elif i == 2:        \n",
    "            money = row[3]\n",
    "            if money == \"\":\n",
    "                r.append(None)\n",
    "                continue\n",
    "            else: \n",
    "                value = float(Decimal(sub(r'[^\\d.]', '', money)))#remove dollar sign, comma, and everything after the .\n",
    "                r.append(value)\n",
    "        elif i == 3: \n",
    "            listing_id  = int(row[0])\n",
    "            r.append(listing_id)    \n",
    "    calendar_data.append(r)\n",
    "\n",
    "\n",
    "calendar_data_np = np.array(calendar_data)\n",
    "print(calendar_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "240f7975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews columns:\n",
      " ['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n",
      "reviews data:\n",
      " [['1178162' '4724140' '2013-05-21' '4298113' 'Olivier'\n",
      "  \"My stay at islam's place was really cool! Good location, 5min away from subway, then 10min from downtown. The room was nice, all place was clean. Islam managed pretty well our arrival, even if it was last minute ;) i do recommand this place to any airbnb user :)\"]\n",
      " ['1178162' '4869189' '2013-05-29' '6452964' 'Charlotte'\n",
      "  'Great location for both airport and city - great amenities in the house: Plus Islam was always very helpful even though he was away']\n",
      " ['1178162' '5003196' '2013-06-06' '6449554' 'Sebastian'\n",
      "  \"We really enjoyed our stay at Islams house. From the outside the house didn't look so inviting but the inside was very nice! Even though Islam himself was not there everything was prepared for our arrival. The airport T Station is only a 5-10 min walk away. The only little issue was that all the people in the house had to share one bathroom. But it was not really a problem and it worked out fine. We would recommend Islams place for a stay in Boston. \"]\n",
      " ...\n",
      " ['7462268' '85797088' '2016-07-13' '77129134' 'Nick'\n",
      "  'The room was very clean as were the bathrooms and kitchen. The bed was also very comfortable. Bathrooms featured shampoo and body was for public use which was a plus along with good wifi and air conditioning. The neighborhood was safe and populated with many students. Conveniently located about a mile from Harvard and Boston University. Many great places too eat are also a 10~ minute walk from the room. Joe was also very helpful in returning an earring to me that I had left in the room. Would definitely stay again.']\n",
      " ['7462268' '97264637' '2016-08-26' '15799803' 'Vid'\n",
      "  \"Staying in Lower Allston at Joe and Nancy's place was fantastic! I am a medical student and was studying at the Massachusetts General Hospital for 6 weeks so it was really important for me to find a place that was clean, private, comfortable, safe and friendly with easy access to Harvard Square/ the red line/ the hospital. Joe's place provided all of this and more! \\n\\nThe room was spacious and clean with air conditioning and a heater. I had easy access to all the facilities I needed including a fully equipped kitchen, laundry facilities and 2 bathrooms. Joe went above and beyond to make sure I had everything I needed and went out and bought an ironing board when I asked if one was available for me to iron my shirts with! All the guests that stayed during my 6 weeks were also respectful and friendly which made my trip even better. \\n\\nThe house is in a pleasant residential area which is quiet at night time but close to all important amenities. The nearest supermarket was only 10 minutes walk away and the number 66 bus route had a stop at the top of the road and had a regular service every 5-10 minutes which took me into Harvard Square within 10 minutes. \\n\\nBetween my excellent hosts and the fantastic location I felt completely at home during my stay and would recommend Joe's place to anyone looking visit Boston without paying the ridiculous price of downtown hotels. It was an absolute pleasure to get to know him and his wife Nancy and I hope they stay in touch in the future. I wish you both all the best! \"]\n",
      " ['7462268' '98550693' '2016-08-31' '90128094' 'Arianna'\n",
      "  \"The room itself and the aprtment were very clean. Joe provided many amenities such as shampoo and towels. Overall I'm very pleased!\"]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Loading reviews.csv into numpy w/o any modification, i.e. w/o switching anything from qualitative to quantitative  \n",
    "'''\n",
    "from collections import defaultdict\n",
    "csv_file = open('archive/reviews.csv', 'r')\n",
    "reader = csv.reader(csv_file, delimiter=',', quotechar='\"')\n",
    "review_columns = []\n",
    "data = []\n",
    "reviews_and_ids = defaultdict(list) #key: listing id --> value: all comments corresponding to that listing id\n",
    "for i, row in enumerate(reader):\n",
    "    if i == 0:\n",
    "        review_columns = row\n",
    "        continue\n",
    "    r = []\n",
    "    for i in range(6):\n",
    "        r.append(row[i])\n",
    "    \n",
    "    listing_id, review_text = row[0], row[-1]\n",
    "    reviews_and_ids[listing_id].append(review_text)\n",
    "    data.append(r)\n",
    "\n",
    "csv_file.close()\n",
    "reviews = np.array(data)\n",
    "print(\"reviews columns:\\n\", review_columns)\n",
    "print(\"reviews data:\\n\", reviews)\n",
    "\n",
    "all_reviews = [ ] #list of reviews \n",
    "#each element of the corpus corresponds to all reviews of one listing concatenated together\n",
    "for listing_id, reviews in reviews_and_ids.items():\n",
    "    reviews_combined = \"\".join(reviews)\n",
    "    all_reviews.append(reviews_combined)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1129c6e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listing_columns\n",
      " ['id', 'listing_url', 'scrape_id', 'last_scraped', 'name', 'summary', 'space', 'description', 'experiences_offered', 'neighborhood_overview', 'notes', 'transit', 'access', 'interaction', 'house_rules', 'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'street', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'city', 'state', 'zipcode', 'market', 'smart_location', 'country_code', 'country', 'latitude', 'longitude', 'is_location_exact', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities', 'square_feet', 'price', 'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights', 'maximum_nights', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'requires_license', 'license', 'jurisdiction_names', 'instant_bookable', 'cancellation_policy', 'require_guest_profile_picture', 'require_guest_phone_verification', 'calculated_host_listings_count', 'reviews_per_month']\n",
      "listings data \n",
      " [['12147973' '31303940' '1' '1' '42.282618795779484' '-71.13306792912681'\n",
      "  1 3 2 '4' '1.5' '2' '3' 3 None 250.0 None None None 35.0 '1' 0.0 '2'\n",
      "  '1125' 10 '0' '0' '0' '0' '0' None None None None None None None 0 0 1\n",
      "  0 0 '1' None]\n",
      " ['3075044' '2572247' '1' '1' '42.286240821867416' '-71.13437396457161' 1\n",
      "  12 0 '2' '1.0' '1' '1' 3 None 65.0 400.0 None 95.0 10.0 '0' 0.0 '2'\n",
      "  '15' 8 '26' '54' '84' '359' '36' '94' '10' '9' '10' '10' '9' '9' 0 1 1\n",
      "  0 0 '1' '1.30']\n",
      " ['6976' '16701' '1' '1' '42.2924378866568' '-71.13576525374667' 1 12 0\n",
      "  '2' '1.0' '1' '1' 3 None 65.0 395.0 1350.0 None None '1' 20.0 '3' '45'\n",
      "  6 '19' '46' '61' '319' '41' '98' '10' '9' '10' '10' '9' '10' 0 0 1 1 0\n",
      "  '1' '0.47']\n",
      " ['1436513' '6031442' '1' '1' '42.28110618827366' '-71.12102117350553' 0\n",
      "  3 0 '4' '1.0' '1' '2' 3 None 75.0 None None 100.0 50.0 '2' 25.0 '1'\n",
      "  '1125' 8 '6' '16' '26' '98' '1' '100' '10' '10' '10' '10' '10' '10' 0 0\n",
      "  1 0 0 '1' '1']\n",
      " ['7651065' '15396970' '1' '1' '42.28451220982457' '-71.1362580468337' 1\n",
      "  3 0 '2' '1.5' '1' '2' 3 None 79.0 None None None 15.0 '1' 0.0 '2' '31'\n",
      "  10 '13' '34' '59' '334' '29' '99' '10' '10' '10' '10' '9' '10' 0 0 0 0\n",
      "  0 '1' '2.25']]\n",
      "neighborhoods data \n",
      " ['Roslindale' 'Roslindale' 'Roslindale' ... 'Charlestown' 'Somerville'\n",
      " 'Somerville']\n",
      "neighborhoods & listing matching \n",
      " [('12147973', 'Roslindale'), ('3075044', 'Roslindale'), ('6976', 'Roslindale'), ('1436513', 'Roslindale'), ('7651065', 'Roslindale')]\n"
     ]
    }
   ],
   "source": [
    "# listings = np.loadtxt('archive/listings.csv', delimiter=',', skiprows = 1)\n",
    "'''\n",
    "but leaving out rows that dont have a value for host_neighborhood  and/or neighborhood \n",
    "\n",
    "'''\n",
    "from re import sub\n",
    "from decimal import Decimal\n",
    "\n",
    "\n",
    "listings_csvfile = open('archive/listings.csv', 'r') \n",
    "reader = csv.reader(listings_csvfile, delimiter=',', quotechar='\"')\n",
    "listings_data = []\n",
    "column = None \n",
    "property_types = {'': 0, 'Condominium': 1, 'Camper/RV': 2, 'House': 3, 'Townhouse': 4, 'Entire Floor': 5, \n",
    "              'Guesthouse': 6, 'Boat': 7, 'Dorm': 8, 'Villa': 9, 'Bed & Breakfast': 10, 'Other': 11, 'Apartment': 12, \n",
    "              'Loft': 13 }\n",
    "\n",
    "room_types = {'Private room': 0, 'Shared room': 1, 'Entire home/apt': 2}\n",
    "beds = {'Couch': 0, 'Airbed':1, 'Pull-out Sofa':2, 'Real Bed':3, 'Futon':4}\n",
    "calendar_updated = {'never': 0, 'yesterday': 1, 'today': 2, '2 days ago': 3, '3 days ago': 4,\n",
    "                    '4 days ago': 5, '5 days ago': 6, '6 days ago': 7, 'a week ago': 8, '1 week ago': 9,\n",
    "                    '2 weeks ago': 10, '3 weeks ago': 11,'4 weeks ago': 12, '5 weeks ago': 13, '6 weeks ago': 14, \n",
    "                    '7 weeks ago': 15,'2 months ago': 16,'3 months ago': 17,'4 months ago': 18,'5 months ago': 19,\n",
    "                    '7 months ago': 20,'6 months ago': 21, '8 months ago': 22,'9 months ago': 23,'10 months ago':24,\n",
    "                    '11 months ago':25,'12 months ago':26, '13 months ago': 27, '14 months ago': 28, '15 months ago': 29, '16 months ago': 30, \n",
    "                    '17 months ago': 31, '18 months ago': 32, '20 months ago': 33, '22 months ago': 34, '30 months ago': 35, \n",
    "                    '23 months ago': 36, '25 months ago': 37 }\n",
    "cancellation_policy = {'flexible': 0, 'moderate': 1, 'strict': 2, 'super_strict_30': 3}\n",
    "indicesSet = set([0,19,32,33,48,49,53,54,55,56,59,65, \\\n",
    "                  67,68,71,72,73,74,76,79,80,81,82,83,84,85,93,94,50,86,89,91,92,51,52,57,\\\n",
    "                 60,61,62,63,64,66,69,90]) #columns included in the numpy array \n",
    "neighborhoods = [ ]\n",
    "neighborhoodMatch = {} #a dictionary that maps a listing to a neighborhood tag in form \"listing_id:neighborhood\"\n",
    "\n",
    "listing_columns = [ ]\n",
    "for index, row in enumerate(reader): \n",
    "    if index == 0:\n",
    "        listing_columns = row\n",
    "        continue\n",
    "    #removing rows without a listed neighborhood in either of these 4 columns that correspond to neighborhood\n",
    "    host_neighbourhood = row[31]\n",
    "    neighbourhood = row[38]\n",
    "    neighbourhood_cleansed = row[39]\n",
    "    neighbourhood_group_cleansed = row[40]\n",
    "    \n",
    "    listing_id = row[0]\n",
    "\n",
    "    if not neighbourhood and not host_neighbourhood \\\n",
    "        and not neighbourhood_cleansed and not neighbourhood_group_cleansed:\n",
    "        continue \n",
    "    #adding neighborhood from whatever column it's stored in\n",
    "    if neighbourhood: \n",
    "        neighborhoods.append(neighbourhood)\n",
    "        neighborhoodMatch[listing_id]=neighbourhood\n",
    "    elif neighbourhood_cleansed:\n",
    "        neighborhoods.append(neighbourhood_cleansed)\n",
    "        neighborhoodMatch[listing_id]=neighbourhood_cleansed\n",
    "    elif neighbourhood_group_cleansed:\n",
    "        neighborhoods.append(neighbourhood_group_cleansed)\n",
    "        neighborhoodMatch[listing_id]=neighbourhood_group_cleansed\n",
    "        \n",
    "        \n",
    "\n",
    "    if index == 0:\n",
    "        columns = row\n",
    "    r  = [ ] #row values\n",
    "    for i in range(95): #i is a column index \n",
    "        if index == 0 and i in indicesSet: #then this is the header column names\n",
    "            r.append(row[i])\n",
    "        elif i == 0 or i == 19 or i == 32 or i == 33 \\\n",
    "            or i == 48 or i == 49 or i == 53 or i == 54 or i == 55 or i == 56 or i == 59 \\\n",
    "            or i == 65 or i == 67 or i == 68 or (i >=71 and i <= 74) or i == 76 or (i >= 79 \\\n",
    "            and i <= 85) or i ==  93 or i == 94: #listing id, host id \n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                val = row[i] \n",
    "                r.append(val)\n",
    "        elif i == 50 or i == 86 or i == 89 or i == 91 or i == 92:\n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                boolean = 0 if row[i] == \"f\" else 1 \n",
    "                r.append(boolean)\n",
    "        elif i == 51:\n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                property_type = property_types[row[i]]\n",
    "                r.append(property_type)\n",
    "        elif i == 52:\n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                room_type = room_types[row[i]] \n",
    "                r.append(room_type)\n",
    "        elif i == 57:\n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                bed = row[i]\n",
    "                r.append(beds[bed])\n",
    "        elif (i >=  60 and i <= 64) or i == 66: \n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                money = row[i]\n",
    "                value = float(Decimal(sub(r'[^\\d.]', '', money)))#remove dollar sign, comma, and everything after the .\n",
    "                r.append(value)\n",
    "        elif i == 69: #calendar_updated col \n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                date = row[i]\n",
    "                r.append(calendar_updated[date])  \n",
    "        elif i == 90:\n",
    "            if row[i] == \"N/A\" or row[i] == \"\":\n",
    "                r.append(None)\n",
    "                continue \n",
    "            else:\n",
    "                policy = row[i]\n",
    "                val = cancellation_policy[(policy)] \n",
    "                r.append(val)\n",
    "        \n",
    "    listings_data.append(r)\n",
    "\n",
    "listings_numerical_data = np.array(listings_data)\n",
    "neighborhoods = np.array(neighborhoods)\n",
    "allLabels, labelsCounts = np.unique(neighborhoods, return_counts=True)\n",
    "print(\"listing_columns\\n\", listing_columns)\n",
    "print(\"listings data \\n\", listings_numerical_data[:5,:]) #first 5 rows\n",
    "print(\"neighborhoods data \\n\", neighborhoods )\n",
    "print(\"neighborhoods & listing matching \\n\", list(neighborhoodMatch.items())[:5]) # first 5 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c032a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # neighborhoods \n",
      " 23\n",
      "Allston-Brighton Count : 432\n",
      "Back Bay Count : 330\n",
      "Beacon Hill Count : 210\n",
      "Brookline Count : 12\n",
      "Cambridge/Somerville Count : 22\n",
      "Charlestown Count : 98\n",
      "Chinatown Count : 84\n",
      "Dorchester Count : 260\n",
      "Downtown Count : 83\n",
      "East Boston Count : 149\n",
      "Fenway/Kenmore Count : 293\n",
      "Hyde Park Count : 32\n",
      "Jamaica Plain Count : 343\n",
      "Mattapan Count : 28\n",
      "Mission Hill Count : 122\n",
      "North End Count : 145\n",
      "Roslindale Count : 56\n",
      "Roxbury Count : 148\n",
      "South Boston Count : 258\n",
      "South End Count : 330\n",
      "Theater District Count : 34\n",
      "West End Count : 74\n",
      "West Roxbury Count : 42\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#CONSOLIDATE BOSTON NEIGHBORHOODS\n",
    "for count, neighborhood in enumerate(neighborhoods):\n",
    "    if neighborhood in ['Cambridge','Harvard Square', 'Somerville']:\n",
    "        neighborhoods[count] = \"Cambridge/Somerville\"\n",
    "    elif neighborhood in ['Allston','Brighton']:\n",
    "        neighborhoods[count] = \"Allston-Brighton\"\n",
    "    elif neighborhood in ['Fenway', 'Longwood Medical Area']:\n",
    "        neighborhoods[count] = \"Fenway/Kenmore\"\n",
    "    elif neighborhood in ['Downtown Crossing','Government Center', 'Financial District', 'Leather District']:\n",
    "        neighborhoods[count] = \"Downtown\"\n",
    "    elif neighborhood == 'Bay Village':\n",
    "        neighborhoods[count] = \"Theater District\"\n",
    "    elif neighborhood == 'Chestnut Hill':\n",
    "        neighborhoods[count] = \"Brookline\"\n",
    "    elif neighborhood == 'South Boston Waterfront':\n",
    "        neighborhoods[count] = \"South Boston\"\n",
    "allLabels, labelsCounts = np.unique(neighborhoods, return_counts=True)\n",
    "print(\"total # neighborhoods \\n\", len(allLabels) )\n",
    "indices = np.arange(1,labelsCounts.shape[0]+1)\n",
    "plt.bar(indices, labelsCounts, width=0.8, tick_label=allLabels)\n",
    "for i in range(labelsCounts.shape[0]):\n",
    "    print(allLabels[i], \"Count :\", labelsCounts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7f04a",
   "metadata": {},
   "source": [
    "\n",
    "Christine's to-dos:\n",
    "-  remove stuff internally used\n",
    "- leave dates in date form \n",
    "- join on the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31739a",
   "metadata": {},
   "source": [
    "Text Analysis\n",
    "- Remove neighborhood names from text-based feature columns used for training\n",
    "- Bag of words: tfid vectorization\n",
    "- Link reviews to correct neighborhood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85175f5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/16/sl2ndym15737c2463lvz9tx80000gn/T/ipykernel_56138/3651609816.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mlistingID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "#Here is where Jiawei and Sara will do text analysis\n",
    "# split data by neighborhood\n",
    "\n",
    "# def readSpamData(ham_filename, spam_filename):\n",
    "#     DATA = []\n",
    "\n",
    "#     # Read in ham messages from file\n",
    "#     ham_file = open(ham_filename, 'r')\n",
    "#     messages = ham_file.read().split('*****@@@@@%%%%%*****@@@@@%%%%%')\n",
    "#     for message in messages: DATA.append([message, 0])\n",
    "#     ham_file.close()\n",
    "    \n",
    "#     # Read in spam messages from file\n",
    "#     spam_file = open(spam_filename, 'r')\n",
    "#     messages = spam_file.read().split('*****@@@@@%%%%%*****@@@@@%%%%%')\n",
    "#     for message in messages: DATA.append([message, 1])\n",
    "#     spam_file.close()\n",
    "\n",
    "#     random.shuffle(DATA)  # Shuffle\n",
    "#     return [row[0] for row in DATA], [row[1] for row in DATA]\n",
    "\n",
    "# corpus, labels = readSpamData('ham.txt', 'spam.txt')\n",
    "\n",
    "\n",
    "corpus = reviews[:,5] \n",
    "listingID = reviews[:,0]\n",
    "labels = []\n",
    "for i in listingID:\n",
    "    labels.append(neighborhoodMatch[i])\n",
    "print(len(corpus))\n",
    "print(len(labels))\n",
    "print(len(reviews))\n",
    "print(corpus[:5])\n",
    "print(listingID[:5])\n",
    "print(labels[:5])\n",
    "\n",
    "\n",
    "# Separate into training and testing data\n",
    "TEST_SIZE = 0.25  \n",
    "# MAKE SURE ITS SPLIT BEFORE USING!!!!!\n",
    "\n",
    "separator = int((1.0 - TEST_SIZE)*len(corpus))\n",
    "corpus_train = corpus[:separator]\n",
    "labels_train = labels[:separator]\n",
    "corpus_test = corpus[separator:]\n",
    "labels_test = labels[separator:]\n",
    "print(len(corpus_train))\n",
    "print(len(labels_train))\n",
    "print(len(corpus_test))\n",
    "print(len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28100a0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/16/sl2ndym15737c2463lvz9tx80000gn/T/ipykernel_56138/225590764.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use individual words as tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Text feature extraction for training data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()  # Use individual words as tokens\n",
    "X_train = vectorizer.fit_transform(corpus_train)\n",
    "y_train = np.array(labels_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "# print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70bf6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text feature extraction for testing data\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "y_test = np.array(labels_test)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Use different classifiers to predict neighborhood label\n",
    "from sklearn import linear_model  # Using sklearn Perceptron classifier\n",
    "from sklearn import ensemble  # Using RandomForest classifier\n",
    "from sklearn import neighbors  # Using nearest neighbors classifier\n",
    "learners = {'Perceptron': linear_model.Perceptron(max_iter=10),\n",
    "#             'RandomForest': ensemble.RandomForestClassifier(),\n",
    "            'kNN': neighbors.KNeighborsClassifier()\n",
    "           }\n",
    "for classifierName in learners:\n",
    "    learners[classifierName].fit(X_train, y_train)\n",
    "    print('Accuracy of ' + classifierName + ':\\t' + str(learners[classifierName].score(X_test, y_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Perceptron weights\n",
    "learner = linear_model.Perceptron(max_iter=10)\n",
    "learner.fit(X_train, y_train)\n",
    "weights = learner.coef_  # Get the learned Perceptron weights\n",
    "# sorted_weights = np.argsort(weights)  # Sort\n",
    "features = vectorizer.get_feature_names()  # Get the features\n",
    "print(weights.shape)\n",
    "\n",
    "print('\\nClassName : weight pair: ')\n",
    "for n in range(weights.shape[0]): \n",
    "    print(\"\\nNeighborhood: \"+str(y_train[n]))\n",
    "    for i in range(25): \n",
    "        print(\"\\nClassName: \"+str(features[i])+\" Weights: \"+str(weights[n,i]))\n",
    "\n",
    "\n",
    "# print('\\nLowest weighted words (indicative of negative sentiment tweets)')\n",
    "# for i in range(25): print(features[sorted_weights[0,i]])\n",
    "# print('\\nHighest weighted words (indicative of positive sentiment tweets)')\n",
    "# for i in range(25): print(features[sorted_weights[0,len(sorted_weights[0])-i-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40338f65",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b71ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data. rows already randomly permuted\n",
    "\n",
    "# Split data into training (80%) and testing (20%).\n",
    "# Use feature scaling to standardize the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = listings_numerical_data\n",
    "y = neighborhoods\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "def scaleData(trainX, testX):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(trainX)\n",
    "    return scaler.transform(trainX), scaler.transform(testX)\n",
    "\n",
    "X_train, X_test = scaleData(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d4c41",
   "metadata": {},
   "source": [
    "split into training and testing\n",
    "- first organize stuff by neighborhood\n",
    "- randomly permute rows of each neighborhood set\n",
    "- then select 25% of each neighborhood for testing and the rest for training\n",
    "- combine the testing components and the training components\n",
    "\n",
    "- **** we also planned to do cross validation, but maybe we can revisit that later?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94234a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (80%) and testing (20%) and randomly permute rows\n",
    "# Use feature scaling to standardize the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "def scaleData(trainX, testX):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(trainX)\n",
    "    return scaler.transform(trainX), scaler.transform(testX)\n",
    "\n",
    "X_train, X_test = scaleData(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3498c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814a489",
   "metadata": {},
   "source": [
    "Create Classification models\n",
    "- kNN\n",
    "- random forest\n",
    "- SVM\n",
    "- Logistic Regression\n",
    "- Neural Network (or Perceptron)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model  # Using sklearn Perceptron classifier\n",
    "from sklearn import ensemble  # Using RandomForest classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import neighbors  # Using nearest neighbors classifier\n",
    "# learners = {'Perceptron': linear_model.Perceptron(max_iter=10),\n",
    "#             'RandomForest': ensemble.RandomForestClassifier(),\n",
    "#             'kNN': neighbors.KNeighborsClassifier(),\n",
    "#             'SVM': SVC(),\n",
    "#             'LogisticRegression': linear_model.LogisticRegression(random_state=42)\n",
    "#            },\n",
    "           }\n",
    "# for classifierName in learners:\n",
    "#     learners[classifierName].fit(X_train, y_train)\n",
    "#     print('Accuracy of ' + classifierName + ':\\t' + str(learners[classifierName].score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is where Jiawei will do NN\n",
    "# Get Perceptron weights\n",
    "# learner = linear_model.Perceptron(max_iter=1)\n",
    "learner.fit(X_train, y_train)\n",
    "weights = learner.coef_  # Get the learned Perceptron weights\n",
    "sorted_weights = np.argsort(weights)  # Sort\n",
    "features = vectorizer.get_feature_names()  # Get the features\n",
    "print('\\nLowest weighted words (indicative of ham)')\n",
    "for i in range(5): print(features[sorted_weights[0,i]])\n",
    "print('\\nHighest weighted words (indicative of spam)')\n",
    "for i in range(5): print(features[sorted_weights[0,len(sorted_weights[0])-i-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f33b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ed455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
